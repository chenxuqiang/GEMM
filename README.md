# GEMM
a simple GEMM

## gemm avx
![avx](https://github.com/chenxuqiang/GEMM/blob/main/photo/gemm.PNG)
如上图所示，我们使用avx指令加速GEMM运算。
* 大致原理如下：
1. 由于float类型的大小为4字节，即4 * 8bits = 32bits；而avx浮点寄存器宽度为256bit，即一个浮点寄存器可以同时支持256/32 = 8个float值，即每条avx指令可以完成8个float类型数据的计算；
2. 其次我们依然采用最初的方法，使用A的一行 * B的一列得到C的一个值这样的计算方法，那么意味着我们每次需要从A的一行中依次取出8个float作为一个计算单元，从B中的一列中依次取出8个float作为一个计算单元。进行乘加计算。
3. 当一列和一行都遍历完成之后，我们得到了一个长度为8的向量，将该向量的每个元素累加到一个值，即最后的计算结果。
4. 依次类推，计算出所有的值，既可以完成矩阵的乘法。
* 过程中需要注意的事项
  * B copy：这个问题来源于我们在取数据的时候，需要得到B矩阵的一列中的连续8个数据，但是由于传入的矩阵是行存储的，因此在行上是内存连续的，但是在列上，内存不是连续的。为了实现上面的功能，我们需要将B矩阵从行连续改成列连续。因此需要加入一个copy函数，具体原理如下图所示：
  ![copyB](https://github.com/chenxuqiang/GEMM/blob/main/photo/copyB.PNG)
  * B copy开销分析， BCopy的开销在于拷贝一次矩阵B，包括load和store数据。它的开销就和B的大小有关系，我们可以看到整个计算过程中，需要遍历一次矩阵A，遍历M次矩阵B。那么整个copyB的开销占用整个计算过程的开销最大为1/M，那么就意味着M越大，copyB占用的开销越小。而当B较小的时候，则由于B的拷贝操作可以预热L1和L2Cache；
* 优化点：
  * 利用SIMD指令加速计算，较好利用CPU寄存器和运算器资源；
  * 寄存器保存中间结果，避免每次计算都要访存，提升流水线；
  * 内存连续访问，避免内存跳跃访问的指针计算开销；
* 待改进点：
  * 使用内存池避免每次copyB的时候都要申请内存开销；
  * 矩阵分块，如果矩阵规模再大一点的话，由于每次计算A的一行，需要遍历一次矩阵B，这会导致数据的复用率低。通过分块计算，复用数据；
  * 预取：利用计算和访存并行，在本轮计算过程中，预取下一轮计算需要的数据到L1 Cache中，减少计算访存比
  * 循环展开：利用浮点计算多发射；
